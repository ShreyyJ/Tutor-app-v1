# OpenAI Configuration (only for LLM, embeddings are local)
OPENAI_API_KEY="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"
pinecone_api_key="pcsk_22tLD5_KtAJboD1zTkAFniEUcVGNr8ph1RQtwjnTo98G9d6hAU2BEm3ERAnM7Hnzhya74w"

# Milvus Configuration  
MILVUS_HOST=localhost
MILVUS_PORT=19530

# HuggingFace Embeddings Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
USE_GPU=false# Local model cache directory

# Streamlit Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Application Settings
LOG_LEVEL=INFO
MAX_UPLOAD_SIZE_MB=50
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_TOP_K=5

# Optional: Enable debug mode
DEBUG=false

# GPU Settings (if available)
CUDA_VISIBLE_DEVICES=0